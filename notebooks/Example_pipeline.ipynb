{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of what a possible pipeline could look like for processing a URL from start to finish.\n",
    "\n",
    "Once finalized this can be implemented as a series of methods in `pipeline.py`.\n",
    "\n",
    "Some questions to discuss:\n",
    "    \n",
    "    - Should we attempt end-to-end processing in one shot or split it into steps\n",
    "    - Implemente these as class methods, then initialize Pipeline() and carry out the steps one at a time?\n",
    "\n",
    "This also highlights some pending issues to deal with in the Scraper and/or Interpreter code, i.e.\n",
    "\n",
    "1. Turn extracted dates into Date Windows\n",
    "2. Turn extracted quantities into integers for saving to DB\n",
    "3. Add step for classifying article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Change these to True to set up the DB the first time\n",
    "i_know_this_will_delete_everything = True\n",
    "initialize_id_test = True\n",
    "initialize_id = False\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from internal_displacement.model.model import init_db\n",
    "\n",
    "db_host = os.environ.get('DB_HOST')\n",
    "\n",
    "if initialize_id:\n",
    "    db_url = 'postgresql://{user}:{password}@{db_host}/{db}'.format(\n",
    "        user='jupyter', password='jupyter', db_host=db_host, db='id')\n",
    "    init_db(db_url, i_know_this_will_delete_everything=i_know_this_will_delete_everything)\n",
    "    \n",
    "if initialize_id_test:\n",
    "    db_url = 'postgresql://{user}:{password}@{db_host}/{db}'.format(\n",
    "        user='tester', password='tester', db_host=db_host, db='id_test')\n",
    "    init_db(db_url, i_know_this_will_delete_everything=i_know_this_will_delete_everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "from internal_displacement.model.model import Status, Session, Category, Article, Content, Country, CountryTerm, \\\n",
    "    Location, Report, ReportDateSpan, ArticleCategory, Base\n",
    "from internal_displacement.scraper import Scraper\n",
    "from internal_displacement.interpreter import Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-up the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine(db_url)\n",
    "Session.configure(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Receive the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.independent.co.uk/news/world/asia/160-killed-and-hundreds-left-stranded-by-flooding-across-afghanistan-and-pakistan-8746566.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new article based upon the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "article = Article(url=url, status=Status.NEW)\n",
    "session.add(article)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Scraper, and attempt to download the url and update article attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scraper = Scraper()\n",
    "content, publish_date, title, content_type, authors, domain = scraper.scrape(url)\n",
    "\n",
    "if content == 'retrieval_failed':\n",
    "    # Not implemented, but here would set status to processing failed\n",
    "    pass\n",
    "else:\n",
    "    session.query(Article).filter(Article.id == article.id).\\\n",
    "    update({\"domain\": domain, \"status\": Status.FETCHED, \"title\": title, \"publication_date\": publish_date,\n",
    "           \"authors\": \", \".join(authors)})\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the article content to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = Content(article_id=article.id, retrieval_date=datetime.now(), \\\n",
    "                  content=content, content_type=content_type)\n",
    "session.add(content)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-up and initialize the Interpreter for carrying out report extraction etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the spacy engine\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the terms we want to use for article extraction\n",
    "person_reporting_terms = [\n",
    "    'displaced', 'evacuated', 'forced', 'flee', 'homeless', 'relief camp',\n",
    "    'sheltered', 'relocated', 'stranded', 'stuck', 'stranded', \"killed\", \"dead\", \"died\", \"drown\"\n",
    "]\n",
    "\n",
    "structure_reporting_terms = [\n",
    "    'destroyed', 'damaged', 'swept', 'collapsed',\n",
    "    'flooded', 'washed', 'inundated', 'evacuate'\n",
    "]\n",
    "\n",
    "person_reporting_units = [\"families\", \"person\", \"people\", \"individuals\", \"locals\", \"villagers\", \"residents\",\n",
    "                            \"occupants\", \"citizens\", \"households\", \"life\"]\n",
    "\n",
    "structure_reporting_units = [\"home\", \"house\", \"hut\", \"dwelling\", \"building\", \"shop\", \"business\", \"apartment\",\n",
    "                                     \"flat\", \"residence\"]\n",
    "\n",
    "relevant_article_terms = ['Rainstorm', 'hurricane',\n",
    "                          'tornado', 'rain', 'storm', 'earthquake']\n",
    "relevant_article_lemmas = [t.lemma_ for t in nlp(\n",
    "    \" \".join(relevant_article_terms))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Intialize the interpreter\n",
    "\n",
    "data_path = '../data'\n",
    "interpreter = Interpreter(nlp, person_reporting_terms, structure_reporting_terms, person_reporting_units,\n",
    "                          structure_reporting_units, relevant_article_lemmas, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set article status to processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "article.status = Status.PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check and update language attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "article.language = interpreter.check_language(article.content.content)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try and extract reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reports = interpreter.process_article_new(article.content.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process each report in turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for rep in reports:\n",
    "    # Need to fix how quantities are extracted to be integers not strings\n",
    "    report = Report(article_id=article.id, event_term=rep.event_term, subject_term=rep.subject_term,\n",
    "               quantity=0, tag_locations=json.dumps(rep.tag_spans),\n",
    "               analysis_date=datetime.now())\n",
    "    session.add(report)\n",
    "    session.commit()\n",
    "    \n",
    "    # Process each report location in turn\n",
    "    for loc in rep.locations:\n",
    "        country_code = interpreter.country_code(loc)\n",
    "        if country_code:\n",
    "            country = session.query(Country).filter_by(code=country_code).one_or_none() or Country(code=country_code)\n",
    "            session.add(country)\n",
    "            session.commit()\n",
    "            location = Location(description=loc, country=country)\n",
    "            session.add(location)\n",
    "            session.commit()\n",
    "            report.locations.append(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the article relevance status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "status = len(article.reports) > 0\n",
    "article.relevance = status\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Set report status to processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article.status = Status.PROCESSED\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PENDING\n",
    "\n",
    "- Insert and add date spans to reports\n",
    "- Call pre-trained ML model to classify article and save category / categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
