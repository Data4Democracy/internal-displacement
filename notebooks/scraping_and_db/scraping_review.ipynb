{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Review\n",
    "\n",
    "Aims:\n",
    "\n",
    "- Import database and examine poorly scraped articles\n",
    "- Check for retrieval failed\n",
    "- Check for short/nonsense text\n",
    "- Check for common domains that are improperly scraped\n",
    "- Check for extra material scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib import parse\n",
    "from newspaper import Article\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def postgres_to_df(db, table):\n",
    "    engine = create_engine('postgres://postgres:password@localhost/{}'.format(db))\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    with engine.connect() as conn, conn.begin():\n",
    "        df = pd.read_sql_table(table, conn)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_article_1 = postgres_to_df('id_test', 'article')\n",
    "df_article_2 = postgres_to_df('id_test_simon', 'article')\n",
    "df_content_1 = postgres_to_df('id_test', 'content')\n",
    "df_content_2 = postgres_to_df('id_test_simon', 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1 = df_article_1.merge(df_content_1, left_on='id', right_on='article', how='outer')\n",
    "df_2 = df_article_2.merge(df_content_2, left_on='id', right_on='article', how='outer')\n",
    "df = pd.concat([df_1, df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_url(url):\n",
    "    url = parse.urlparse(url)\n",
    "    return url.hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['domain'] = df['url'].apply(lambda x: parse_url(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles that Failed to Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_failed = df[df['status'] == 'fetching failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_success = df[df['status'] != 'fetching failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 40% of articles fail to retrieve. Most disappointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failures 41.65561562786902\n",
      "Successes 58.344384372130975\n"
     ]
    }
   ],
   "source": [
    "print(\"Failures\", len(df_failed)/len(df)*100)\n",
    "print(\"Successes\", len(df_success)/len(df)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No single domain was responsible for a large percentage of the failures, but some crop up much more often than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hosted.ap.org             1.114240\n",
      "www.nigeriasun.com        0.636709\n",
      "siouxcityjournal.com      0.624464\n",
      "beatricedailysun.com      0.612220\n",
      "www.yahoo.com             0.587731\n",
      "www.sfgate.com            0.575487\n",
      "english.wafa.ps           0.538754\n",
      "lacrossetribune.com       0.489776\n",
      "tucson.com                0.465287\n",
      "thetandd.com              0.453043\n",
      "journalstar.com           0.453043\n",
      "www.ksby.com              0.428554\n",
      "www.hawaiinewsnow.com     0.416310\n",
      "rapidcityjournal.com      0.404065\n",
      "www.shorelinemedia.net    0.391821\n",
      "www.chron.com             0.391821\n",
      "www.omaha.com             0.391821\n",
      "missoulian.com            0.391821\n",
      "trib.com                  0.391821\n",
      "www.mynews13.com          0.379576\n",
      "Name: domain, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_failed['domain'].value_counts(normalize=True)[0:20] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 404 Errors (hosted.ap.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hosted_ap = df_failed['url'][df_failed['domain'] == 'hosted.ap.org']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_articles(url):\n",
    "    a = Article(url)\n",
    "    a.download()\n",
    "    a.parse()\n",
    "    return a.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Article(hosted_ap.iloc[0])\n",
    "a.download()\n",
    "a.is_downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AP articles are note downloading at all. Checking the error code sees that we return a 404. Currently our scraper does not return status code, so it's hard to distinguish why articles are not retrieving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = requests.get(hosted_ap.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Get articles to return status code**\n",
    "\n",
    "Possible solution in `scraper.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domains that also returned 404:\n",
    "\n",
    "- siouxcityjournal.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_article(self, url):\n",
    "    a = newspaper.Article(url)\n",
    "    a.download()\n",
    "    if a.is_downloaded:\n",
    "        a.parse()\n",
    "        article_domain = a.source_url\n",
    "        article_title = a.title\n",
    "        article_authors = a.authors\n",
    "        article_pub_date = a.publish_date\n",
    "        article_text = remove_newline(a.text)\n",
    "        # tag the type of article\n",
    "        # currently default to text but should be able to determine img/video\n",
    "        # etc\n",
    "        article_content_type = 'text'\n",
    "        return article_text, article_pub_date, article_title, article_content_type, article_authors, article_domain\n",
    "    else:  # Temporary fix to deal with https://github.com/codelucas/newspaper/issues/280\n",
    "        a = requests.get(url)\n",
    "        status = a.status_code\n",
    "        return status_code, None, \"\", datetime.datetime.now(), \"\", \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failed but Return to tatus Code 200 (nigeriasun.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nigeriasun = df_failed['url'][df_failed['domain'] == 'www.nigeriasun.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "statuses= []\n",
    "for url in nigeriasun:\n",
    "    c = requests.get(url, headers=headers)\n",
    "    statuses.append(c.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nigeriasun) - sum([s==200 for s in statuses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nigeria Sun articles were possibly unavailable at the time of scraping, but are now returning a status code 200.\n",
    "\n",
    "**2. Retry articles that failed to fetch at a later date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_urls = df_failed['url'][df_failed['domain'] == 'beatricedailysun.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = []\n",
    "for url in test_urls:\n",
    "    c = requests.get(url, headers=headers)\n",
    "    statuses.append(c.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404]\n"
     ]
    }
   ],
   "source": [
    "print(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english.wafa.ps              0.028849\n",
       "reliefweb.int                0.011627\n",
       "www.dailymail.co.uk          0.008655\n",
       "www.yahoo.com                0.008655\n",
       "hosted2.ap.org               0.007955\n",
       "www.worldbulletin.net        0.007518\n",
       "humanitariannews.org         0.005857\n",
       "news.trust.org               0.005420\n",
       "allafrica.com                0.004633\n",
       "www.castanet.net             0.004546\n",
       "newsviewsnreviews.com        0.004284\n",
       "newsok.com                   0.003846\n",
       "www.business-standard.com    0.003759\n",
       "www.palestinemonitor.org     0.003584\n",
       "www.dailytelegraph.com.au    0.003322\n",
       "abcnews.go.com               0.003060\n",
       "m.philstar.com               0.003060\n",
       "en.farsnews.com              0.003060\n",
       "www.newsnow.in               0.002972\n",
       "www.washingtontimes.com      0.002885\n",
       "Name: domain, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_success['domain'].value_counts(normalize=True)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code 400 Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot index with vector containing NA / NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-a933943ca2cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_400\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'40'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/George/miniconda3/envs/d4d-internal-displacement/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/George/miniconda3/envs/d4d-internal-displacement/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2078\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;31m# also raises Exception if object array with NA values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m             \u001b[0;31m# warning here just in case -- previously __setitem__ was\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0;31m# reindexing but __getitem__ was not; it seems more reasonable to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/George/miniconda3/envs/d4d-internal-displacement/lib/python3.6/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                     raise ValueError('cannot index with vector containing '\n\u001b[0m\u001b[1;32m    202\u001b[0m                                      'NA / NaN values')\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot index with vector containing NA / NaN values"
     ]
    }
   ],
   "source": [
    "df_400 = df[df['content'].str.contains('40')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
